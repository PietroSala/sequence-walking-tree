{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sources/sequence_dataset.py\n",
    "%run sources/sequence_walking_tree.py\n",
    "\n",
    "import random \n",
    "\n",
    "SAMPLES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom networkx.drawing.nx_pydot import to_pydot\\nfrom IPython.display import Image, display\\nimport networkx as nx\\n\\ndef generate_tree(g, t, k=0):\\n    newline = \"\\n\"\\n    g.add_node(k, label=f\\'{t[\"test_type\"] if \"test_type\" in t else \"\"}{t[\"test\"] if \"test\" in t else \"\"}{newline + \"true_samples - \"+str(t[\"true_samples\"])+ \" \" if \"true_samples\" in t else \"\" }{newline+\"false_samples - \"+str(t[\"false_samples\"]) if \"false_samples\" in t else \"\" }{newline+str(t[\"probabilities\"])}\\'  )\\n    next_k = k + 1\\n    for key in [True, False]:\\n        if key in t:\\n            current_k, next_k = generate_tree(g, t[key], next_k)\\n            g.add_edge(k, current_k, label= f\\'{key}\\')\\n    return k, next_k\\n\\nfor i,t in enumerate(F.trees):\\n    G = nx.DiGraph()\\n    generate_tree(G,t.tree)\\n    pydot_graph = to_pydot(G)\\n    dot_file_path = f\"tree{i}.dot\"\\n    pydot_graph.write_dot(dot_file_path)\\n    !dot -Tpng tree{i}.dot -o tree{i}.png\\n    #display(Image(f\"tree{i}.png\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from networkx.drawing.nx_pydot import to_pydot\n",
    "from IPython.display import Image, display\n",
    "import networkx as nx\n",
    "\n",
    "def generate_tree(g, t, k=0):\n",
    "    newline = \"\\n\"\n",
    "    g.add_node(k, label=f'{t[\"test_type\"] if \"test_type\" in t else \"\"}{t[\"test\"] if \"test\" in t else \"\"}{newline + \"true_samples - \"+str(t[\"true_samples\"])+ \" \" if \"true_samples\" in t else \"\" }{newline+\"false_samples - \"+str(t[\"false_samples\"]) if \"false_samples\" in t else \"\" }{newline+str(t[\"probabilities\"])}'  )\n",
    "    next_k = k + 1\n",
    "    for key in [True, False]:\n",
    "        if key in t:\n",
    "            current_k, next_k = generate_tree(g, t[key], next_k)\n",
    "            g.add_edge(k, current_k, label= f'{key}')\n",
    "    return k, next_k\n",
    "\n",
    "for i,t in enumerate(F.trees):\n",
    "    G = nx.DiGraph()\n",
    "    generate_tree(G,t.tree)\n",
    "    pydot_graph = to_pydot(G)\n",
    "    dot_file_path = f\"tree{i}.dot\"\n",
    "    pydot_graph.write_dot(dot_file_path)\n",
    "    !dot -Tpng tree{i}.dot -o tree{i}.png\n",
    "    #display(Image(f\"tree{i}.png\"))\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_event_logs(csv_path):\n",
    "    r = pd.read_csv(csv_path)\n",
    "    return list(r[\"sequence\"].apply(lambda x: eval(x) )), list(r[\"class\"])\n",
    "\n",
    "X,Y = read_event_logs(\"datasets/20240124_1525_fitbit_p02_quartiles.csv\")\n",
    "\n",
    "Z = SequenceDataset()\n",
    "Z.fit(X[:SAMPLES],Y[:SAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceWalkingForest():\n",
    "\n",
    "    def __init__(self, number_of_trees = 10, tree_parameters = {}):\n",
    "        self.number_of_trees = number_of_trees\n",
    "        self.tree_parameters = tree_parameters\n",
    "        self.trees        = []\n",
    "        self.tree_weights = []\n",
    "        self.tree_confusion_matrices = []\n",
    "\n",
    "    def fit(self, z, weight_index = 0):\n",
    "        z_size = len(z.raw_x)\n",
    "        id_set = {i for i in range(z_size)}.difference({ i for i,_ in  z.excluded_positions(weight_index) })\n",
    "        id_list = list(id_set)\n",
    "        train_size = len(id_set)\n",
    "        for i in range(self.number_of_trees):\n",
    "            train_index = - (2*i + 1)\n",
    "            score_index = - (2*i + 2)\n",
    "            z.sample_df[train_index] = 0\n",
    "            z.sample_df[score_index] = 0\n",
    "            for i in range(len(z.sample_df)):\n",
    "                if i not in id_set:\n",
    "                    z.sample_df.loc[i, score_index] = 1\n",
    "            for _ in range(train_size):\n",
    "                j = random.choice(id_list)\n",
    "                z.sample_df.loc[j, train_index] = z.sample_df.loc[j, train_index] + 1\n",
    "                z.sample_df.loc[j, score_index] = 1\n",
    "            self.trees.append(self.fit_tree(z, train_index, score_index))\n",
    "            self.tree_weights.append(self.compute_weight(z,score_index))\n",
    "            self.tree_confusion_matrices.append(self.compute_confusion_matrix(z,score_index))\n",
    "\n",
    "    def fit_tree(self, z, train_index, score_index):\n",
    "        r = SequenceWalkingTree(**self.tree_parameters)\n",
    "        r.fit(z, train_index)\n",
    "        z.predictions[score_index] = r.predict(z, score_index)\n",
    "        self.compute_weight(z, score_index)\n",
    "        return r\n",
    "    \n",
    "    def class_prediction_merge(self, z, score_index):\n",
    "        return pd.merge(z.sample_df[['class']], z.predictions[score_index][['prediction']], left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    def compute_weight(self, z, score_index):\n",
    "        merged = self.class_prediction_merge(z, score_index)\n",
    "        return (merged[\"class\"] == merged[\"prediction\"]).mean()\n",
    "    \n",
    "    def compute_confusion_matrix(self, z, score_index):\n",
    "        c = list(Z.classes)\n",
    "        c.sort()\n",
    "        merged = self.class_prediction_merge(z, score_index)\n",
    "        r = pd.DataFrame([{ \"prediction\":  x, \"class\": y, \"count\": 0  } for x in c for y in c  ])\n",
    "        r.set_index([\"prediction\", \"class\"], inplace=True,drop=True)\n",
    "        for i in range(len(merged)):\n",
    "            x, y = merged.iloc[i][\"prediction\"], merged.iloc[i][\"class\"]\n",
    "            r.loc[(x,y), \"count\"] += 1\n",
    "        return r\n",
    "    \n",
    "    def predict(self,z, weight_index = 0, start_index=1, include_class = True, keep_predictions = False):\n",
    "        all_predictions = [] \n",
    "        for i in range(len(self.trees)):\n",
    "            z.sample_df[start_index + i] = z.sample_df[weight_index]\n",
    "            z.predictions[start_index + i] = self.trees[i].predict(z, start_index + i)\n",
    "            if i == 0:\n",
    "                all_predictions = z.predictions[start_index + i][[\"prediction\"]]\n",
    "            else:\n",
    "                all_predictions = pd.merge(all_predictions, z.predictions[start_index + i][[\"prediction\"]], suffixes=(f\"_{i-1}\", f\"_{i}\"), left_index=True, right_index=True, how=\"inner\")\n",
    "         \n",
    "        voting = pd.merge(SequenceWalkingForest.majority(all_predictions), self.weighted(all_predictions), left_index=True, right_index=True, how='inner')\n",
    "        voting = pd.merge(voting, self.track_record(all_predictions), left_index=True, right_index=True, how='inner')\n",
    "        if keep_predictions:\n",
    "           voting = pd.merge(voting, all_predictions, left_index=True, right_index=True, how='inner' )\n",
    "        if include_class:\n",
    "            excluded_samples = {i for i, _ in z.excluded_positions(weight_index)}\n",
    "            voting = pd.merge(z.sample_df.loc[excluded_samples][\"class\"],voting, left_index=True, right_index=True, how='inner')\n",
    "        z.forest_prediction[weight_index] = voting\n",
    "        return voting   \n",
    "\n",
    "    @staticmethod\n",
    "    def majority(all_predictions):   \n",
    "        r = all_predictions.apply(lambda row: pd.Series(list(row)).value_counts().idxmax(), axis=1) \n",
    "        r.name = \"majority\"\n",
    "        return r   \n",
    "\n",
    "    def best_weight(self, list):\n",
    "        w = {c:0 for c in set(list)}\n",
    "        for i, c in enumerate(list):\n",
    "            w[c] = w[c] + self.tree_weights[i]\n",
    "        return max(w,key=lambda k: w[k])\n",
    "\n",
    "    def weighted(self, all_predictions):\n",
    "        r = all_predictions.apply(lambda row: self.best_weight(list(row)), axis=1)\n",
    "        r.name = \"weighted\"\n",
    "        return r\n",
    "    \n",
    "    def best_track_record(self,list):\n",
    "        w = {c:0 for c in set(list)}\n",
    "        for i, c in enumerate(list):\n",
    "            col = self.tree_confusion_matrices[i].loc[c][\"count\"]\n",
    "            if col.sum() > 0:\n",
    "                probability = col/col.sum()\n",
    "                for k in w.keys():\n",
    "                    w[k] = w[k] + probability.loc[k]\n",
    "        return max(w,key=lambda k: w[k])    \n",
    "            \n",
    "    def track_record(self, all_predictions):\n",
    "        r = all_predictions.apply(lambda row: self.best_track_record(list(row)), axis=1)\n",
    "        r.name = \"track_record\"\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.sample_df.loc[15:,0 ] = 0\n",
    "Z.predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = SequenceWalkingForest(number_of_trees=20)\n",
    "F.fit(Z,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/_mh728qx5t16xhvl4mmhwzr40000gn/T/ipykernel_88863/3300932744.py:72: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  voting = pd.merge(z.sample_df.loc[excluded_samples][\"class\"],voting, left_index=True, right_index=True, how='inner')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>majority</th>\n",
       "      <th>weighted</th>\n",
       "      <th>track_record</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class  majority  weighted  track_record\n",
       "sample                                         \n",
       "15          0         0         0             0\n",
       "16          2         1         1             3\n",
       "17          3         1         1             1\n",
       "18          0         3         1             1\n",
       "19          3         3         3             3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.predict(Z,weight_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "sample class\tmajority\tweighted\ttrack_record\n",
    "15\t0\t0\t0\t0\n",
    "16\t2\t1\t1\t3\n",
    "17\t3\t0\t1\t1\n",
    "18\t0\t3\t2\t1\n",
    "19\t3\t3\t3\t3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
