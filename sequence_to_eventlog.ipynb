{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequence_to_eventlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sequences_to_eventlogs(sequence_files, output_path=\"processed_data/sequences\"):\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    # Process each sequence file in the list\n",
    "    for sequence_file in sequence_files:\n",
    "\n",
    "        print(sequence_file)\n",
    "\n",
    "        # Open the file and process each line\n",
    "        with open(sequence_file, 'r') as file:\n",
    "            classes = []\n",
    "            indices = []\n",
    "            data_values = []\n",
    "            remaining_counts = []\n",
    "            percentage_alpha_counts = []\n",
    "            percentage_beta_counts = []\n",
    "            line_numbers = []  # New column for line numbers\n",
    "\n",
    "            for line_number, line in tqdm(enumerate(file, start=1)):\n",
    "                # Split the line into class and sequence recognized by tab\n",
    "                parts = line.strip().split('\\t')\n",
    "                class_label = parts[0]\n",
    "                sequence_data = parts[1]\n",
    "\n",
    "                # Process each data element in the sequence\n",
    "                for index, data_value in enumerate(sequence_data.split()):\n",
    "                    classes.append(class_label)\n",
    "                    indices.append(index)\n",
    "                    data_values.append(data_value)\n",
    "                    line_numbers.append(line_number)\n",
    "\n",
    "                    # Calculate the remaining count\n",
    "                    remaining_sequence_data = ' '.join(sequence_data.split()[index + 1:])\n",
    "                    remaining_count = remaining_sequence_data.count(data_value)\n",
    "                    remaining_counts.append(remaining_count)\n",
    "\n",
    "                    # Calculate Percentage_Alpha (remaining of the data divided by remained elements to visit)\n",
    "                    total_remaining_alpha = len(remaining_sequence_data.split())\n",
    "                    percentage_alpha_count = 0 if total_remaining_alpha == 0 else remaining_count / total_remaining_alpha\n",
    "                    percentage_alpha_counts.append(percentage_alpha_count)\n",
    "\n",
    "                    # Calculate Percentage_Beta (remaining of the data divided by remained data to visit)\n",
    "                    total_occurrences_beta = sequence_data.count(data_value)\n",
    "                    if total_occurrences_beta == 0:\n",
    "                        percentage_beta_count = 0  # Avoid division by zero\n",
    "                    else:\n",
    "                        percentage_beta_count = remaining_sequence_data.count(data_value) / total_occurrences_beta\n",
    "                    percentage_beta_counts.append(percentage_beta_count)\n",
    "\n",
    "            # Create a DataFrame from the lists\n",
    "            df = pd.DataFrame({\n",
    "                'Class': classes,\n",
    "                'Index': indices,\n",
    "                'Data': data_values,\n",
    "                'Remaining': remaining_counts,\n",
    "                'Percentage_Alpha': percentage_alpha_counts,\n",
    "                'Percentage_Beta': percentage_beta_counts,\n",
    "                'I': line_numbers\n",
    "            })\n",
    "\n",
    "            # Save individual DataFrame as CSV\n",
    "            file_name = os.path.splitext(os.path.basename(sequence_file))[0]  # Extract filename without extension\n",
    "            output_file = os.path.join(output_path, f\"{file_name}_eventlogs.csv\")\n",
    "            df.to_csv(output_file, index=False)\n",
    "\n",
    "            df[\"dataset\"], _ = os.path.splitext(os.path.basename(file_name))\n",
    "\n",
    "            # Append the DataFrame to the list for later concatenation\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    # Concatenate all individual DataFrames into one total DataFrame\n",
    "    total_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    return total_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "sequence_files_text = [] #lists of sequences file in the format class sequence\n",
    "\n",
    "# Get the total DataFrame\n",
    "eventlogs_df = sequences_to_eventlogs(sequence_files_text)\n",
    "print(\"Total Eventlogs DataFrame\")\n",
    "print(eventlogs_df)\n",
    "\n",
    "# Save the total DataFrame as CSV\n",
    "eventlogs_df.to_csv(\"processed_data/sequences/\") #oick a name for the full file collect all the event logs converted from sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlogs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
